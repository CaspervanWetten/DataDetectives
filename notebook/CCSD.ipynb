{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537efa65-314d-485b-978e-84499a716f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycountry pandas regex requests plotly dash p_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d7df0-fb4b-4e0f-9d6c-50b5c525fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from p_tqdm import p_map, p_umap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08607f46-2f57-4d6c-a88c-7c7a78caba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit zijn meer algehele, saaie helper functies:\n",
    "\n",
    "def FilterEmptyDict(input_dict):\n",
    "    \"\"\"\n",
    "    Filter out empty entries (values) from a dictionary.\n",
    "    Args: input_dict (dict): The dictionary to filter.\n",
    "    Returns: dict: A new dictionary with empty entries removed.\n",
    "    \"\"\"\n",
    "    return {key: val for key, val in input_dict.items() if val}\n",
    "\n",
    "def DownloadFile(url, write_location):\n",
    "    \"\"\"\n",
    "    Download a file from a given URL and save it to a specified location.\n",
    "    Args: url (str): The URL of the file to download; write_location (str): The path where the downloaded file will be saved.\n",
    "    Returns: str or file: The path to the saved file or an error message if the download fails.\n",
    "    \"\"\"\n",
    "    #TODO If internet shits the bed halfway through, it'll crash, find a way to not have this happen lol\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading data\")\n",
    "        folder_path = os.path.dirname(write_location)\n",
    "        with open(write_location, 'wb') as file:\n",
    "            for data in response.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                file.write(data)\n",
    "        progress_bar.close()\n",
    "        return write_location\n",
    "    else:\n",
    "        return f\"Exited with {response.status_code} as error\"\n",
    "\n",
    "def ExtractZip(zip_file, extract_path):\n",
    "    \"\"\"\n",
    "    Extract a ZIP file to a specified location.\n",
    "    Args: zip_file (str): The path to the ZIP file to extract; extract_path (str): The path where the ZIP file will be extracted.\n",
    "    Returns: str or file: The path to the extracted folder or an error message if extraction fails.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(extract_path):\n",
    "            os.makedirs(extract_path)\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        with tqdm(total=total_files, desc=\"Extracting data\") as pbar:\n",
    "            for member in zip_ref.infolist():\n",
    "                zip_ref.extract(member, extract_path)\n",
    "                pbar.update(1)\n",
    "    return extract_path\n",
    "\n",
    "def GenerateStationIDs(folderPath):\n",
    "    \"\"\"\n",
    "    Reads the stations file and generates a dict with IDs and the countries\n",
    "    Args: the folderpath to the stations file\n",
    "    Return: dictionary: {ID : Country}; note that {country} is formatted in ISO3116 alpha-2\n",
    "    \"\"\"\n",
    "    with open(folderPath + 'stations.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = lines[17:]\n",
    "        f.close()\n",
    "    reg = r\"[\\s]*(\\d+),([\\w\\W\\s]*),([a-zA-Z]{2})\"\n",
    "    CountryIDs = {}\n",
    "    for line in lines:\n",
    "        m = re.match(reg, line)\n",
    "        if m:\n",
    "            country = m.group(3)\n",
    "            stationId = str(m.group(1)).zfill(5)\n",
    "            CountryIDs[stationId] = country\n",
    "    return CountryIDs\n",
    "\n",
    "def RenameFiles(folderPath, CountryIDs, reg=r\"TG_STAID0(\\d*)\", group=1):\n",
    "    \"\"\"\n",
    "    Renames all the files in a folder if it matches the given group in the regex, then renames the file\n",
    "    Args: the folderpath, dictionary that looks like {regex_match : new_name}, regex, group\n",
    "    Return: none\n",
    "    \"\"\"\n",
    "    for file in os.listdir(folderPath):\n",
    "        match = re.match(reg, file)\n",
    "        if not match:\n",
    "            continue\n",
    "        stationId = match.group(group)\n",
    "        newName = CountryIDs[stationId] + stationId + '.txt'\n",
    "        os.rename(os.path.join(folderPath, file), os.path.join(folderPath, newName))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f3613-9fd6-4538-888e-b90d39bbd8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GenerateTemperatureDataframes(filePath):\n",
    "    \"\"\"\n",
    "    Generates a pandas DataFrame from a CSV file containing temperature data.\n",
    "    Parameters: filePath (str): The path to the CSV file, regex matching on (text/)*(countryName)(number)\n",
    "    Returns: tuple: A tuple containing the country name and the generated DataFrame.\n",
    "    \"\"\"\n",
    "    if re.match(r\"[a-zA-Z/]*/([a-zA-Z\\ ]+)(\\d+)\" ,filePath):\n",
    "        country = re.match(r\"[a-zA-Z/]*/([a-zA-Z\\ ]+)(\\d+)\", filePath).group(1)\n",
    "    else:\n",
    "        print(f\"No match with {filePath}\")\n",
    "        return False, False      \n",
    "    with open(filePath, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None, skiprows=21, names=[\"STAID\", \"SOUID\", \"DATE\", \"TG\", \"Q_TG\"], usecols=[\"DATE\", \"TG\", \"Q_TG\"])\n",
    "    df = df[df[\"Q_TG\"].astype(int).isin([0, 1])]\n",
    "    df[\"TG\"] = df[\"TG\"].astype(float) / 10\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%Y%m%d\").dt.strftime('%Y-%m')\n",
    "    df = df[[\"DATE\", \"TG\"]]\n",
    "    df = df.rename(columns={'DATE': 'Date', 'TG': 'Temperature'})\n",
    "    return country, df\n",
    "\n",
    "def CleanTemperatureDataframes(results, dataframeDict, folderPath = \"data/temperature/\", save = False):\n",
    "    \"\"\"\n",
    "    Cleans and processes temperature dataframes.\n",
    "    Parameters: results (list): A list of tuples containing country names and their respective dataframes.\n",
    "        dataframeDict (dict): A dictionary to store the cleaned dataframes.\n",
    "        folderPath (str): The path to the folder where the cleaned dataframes will be saved.\n",
    "        save (bool): A flag indicating whether to save the cleaned dataframes to disk.\n",
    "    Returns: dict: A dictionary containing cleaned dataframes grouped by country name.\n",
    "    \"\"\"\n",
    "    for result in results:\n",
    "        country = result[0]\n",
    "        df = result[1]\n",
    "        if country in dataframeDict.keys():\n",
    "            dataframeDict[country].append(df)\n",
    "    #Filter out the empty countries:\n",
    "    dataframeDict = {key: val for key, val in dataframeDict.items() if val}\n",
    "    #Average the temperatures of the same days\n",
    "    for country, dfList in dataframeDict.items():\n",
    "            concated = pd.concat(dfList, ignore_index=True)\n",
    "            dataframeDict[country] = concated.groupby('Date')['Temperature'].mean().round().reset_index()\n",
    "    #Legacy Saving Code, I'm unsure if it actually works\n",
    "    if save:    \n",
    "        for key, value in dataframeDict.items():\n",
    "            value.to_csv(folderPath+str(key)+\".csv\", index=False)\n",
    "    return dataframeDict\n",
    "\n",
    "def CombineSavedCSV(folder_path):\n",
    "    #Dit is Legacy Code, ik kan je oprecht niet met zekerheid vertellen of het werkt \n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    combined_df = pd.DataFrame(columns=[\"Date\"])\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(folder_path, file))\n",
    "        df.set_index('Date', inplace=True)\n",
    "        country_name = os.path.splitext(file)[0]\n",
    "        df.rename(columns={'Temperature': country_name}, inplace=True)\n",
    "        combined_df = combined_df.join(df, how='outer')\n",
    "    combined_df = combined_df.reindex(sorted(combined_df.columns), axis=1)\n",
    "    return combined_df\n",
    "\n",
    "def CombineCSVDict(dict):\n",
    "    \"\"\"\n",
    "    Combines multiple pandas DataFrames into a single DataFrame.\n",
    "    Parameters: dict: A dictionary containing the DataFrames to be combined.\n",
    "    Returns: A DataFrame containing data from all input DataFrames, matched on the Date column.\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(columns=[\"Date\"])\n",
    "    dfs = [df.set_index('Date').rename(columns={\"Temperature\" : country}) for country, df in dict.items()]\n",
    "    result = pd.concat(dfs, axis=1)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea7d0c-0dbd-47fd-ad8b-c368d0d52421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadTemperatureData(url, folderPath):\n",
    "    \"\"\"\n",
    "    Downloading AND unzipping, what more do you want?!\n",
    "    \"\"\"\n",
    "    download = DownloadFile(url, folderPath+\"download.zip\")\n",
    "    ExtractZip(download, folderPath)\n",
    "\n",
    "def ClassifyTemperatureData(folderPath):\n",
    "    \"\"\"\n",
    "    Calls both the StationID generator and RenameFiles function; thus generates the station IDs and renames all the files\n",
    "    \"\"\"\n",
    "    dict = GenerateStationIDs(folderPath)\n",
    "    RenameFiles(folderPath, dict)\n",
    "\n",
    "def RemoveFile(file):\n",
    "    \"\"\"\n",
    "    Fucks your mother\n",
    "    Args: File, the path to the file that will be removed\n",
    "    \"\"\"\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33435f8e-b087-4b91-81b7-21cc993639b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alles samenkomend ziet het er zo uit:\n",
    "def TemperatureDownloader():\n",
    "    \"\"\"\n",
    "    Downloads, processes, and cleans temperature data from the KNMI Climate Explorer.\n",
    "    \"\"\"\n",
    "    url = \"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_blend_tg.zip\"\n",
    "    folderPath = \"data/temperature/\"\n",
    "    EUList = ['AT', 'BE', 'BG', 'HR', 'CY', 'DK', 'EE', 'FI', 'FR', 'DE', 'IE', 'IT', 'LV', 'LU', 'NL', 'NO', 'PL', 'RO', 'ES', 'SE', 'CH', 'GB']\n",
    "    dataframeDict = {key: [] for key in EUList}\n",
    "\n",
    "    # Prepare all the data for processing\n",
    "    # TODO If internet dies halfway through the download, it fails and the function errors out\n",
    "    # DownloadTemperatureData(url, folderPath)\n",
    "    # ExtractZip(folderPath+\"download.zip\", folderPath)\n",
    "    # ClassifyTemperatureData(folderPath)\n",
    "\n",
    "    \n",
    "    files = [folderPath+filename for filename in os.listdir(folderPath) if filename.endswith(\".txt\")]\n",
    "    results = p_umap(GenerateTemperatureDataframes, files, desc=\"Preparing the data\", num_cpus=3)\n",
    "    # print(\"Generating temperature mapping...\")\n",
    "    # dict = CleanTemperatureDataframes(results, dataframeDict, save=False)\n",
    "    # dict = CombineCSVDict(dict)\n",
    "    # dict.to_csv(folderPath+\"TemperatureData.csv\")\n",
    "    # toClean = [os.path.join(folderPath, file) for file in os.listdir(folderPath) if file.endswith(\".txt\")]\n",
    "    # p_map(RemoveFile, toClean, desc=\"Cleaning leftover files\")\n",
    "    \n",
    "\n",
    "\n",
    "TemperatureDownloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8763c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537efa65-314d-485b-978e-84499a716f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in /opt/conda/lib/python3.11/site-packages (22.3.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.11/site-packages (5.17.0)\n",
      "Requirement already satisfied: dash in /opt/conda/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: p_tqdm in /opt/conda/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from pycountry) (68.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from plotly) (23.1)\n",
      "Requirement already satisfied: Flask<2.3.0,>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from dash) (2.2.5)\n",
      "Requirement already satisfied: Werkzeug<2.3.0 in /opt/conda/lib/python3.11/site-packages (from dash) (2.2.3)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /opt/conda/lib/python3.11/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /opt/conda/lib/python3.11/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /opt/conda/lib/python3.11/site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from dash) (4.7.1)\n",
      "Requirement already satisfied: retrying in /opt/conda/lib/python3.11/site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: ansi2html in /opt/conda/lib/python3.11/site-packages (from dash) (1.8.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from dash) (1.5.6)\n",
      "Requirement already satisfied: tqdm>=4.45.0 in /opt/conda/lib/python3.11/site-packages (from p_tqdm) (4.66.1)\n",
      "Requirement already satisfied: pathos>=0.2.5 in /opt/conda/lib/python3.11/site-packages (from p_tqdm) (0.3.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from p_tqdm) (1.16.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.11/site-packages (from Flask<2.3.0,>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.11/site-packages (from Flask<2.3.0,>=1.0.4->dash) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /opt/conda/lib/python3.11/site-packages (from Flask<2.3.0,>=1.0.4->dash) (8.1.7)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (0.70.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from Werkzeug<2.3.0->dash) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycountry pandas regex requests plotly dash p_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97d7df0-fb4b-4e0f-9d6c-50b5c525fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pycountry\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from p_tqdm import p_map, p_umap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08607f46-2f57-4d6c-a88c-7c7a78caba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit zijn meer algehele, saaie helper functies:\n",
    "\n",
    "def FilterEmptyDict(input_dict):\n",
    "    \"\"\"\n",
    "    Filter out empty entries (values) from a dictionary.\n",
    "    Args: input_dict (dict): The dictionary to filter.\n",
    "    Returns: dict: A new dictionary with empty entries removed.\n",
    "    \"\"\"\n",
    "    return {key: val for key, val in input_dict.items() if val}\n",
    "\n",
    "def DownloadFile(url, write_location):\n",
    "    \"\"\"\n",
    "    Download a file from a given URL and save it to a specified location.\n",
    "    Args: url (str): The URL of the file to download; write_location (str): The path where the downloaded file will be saved.\n",
    "    Returns: str or file: The path to the saved file or an error message if the download fails.\n",
    "    \"\"\"\n",
    "    #TODO If internet shits the bed halfway through, it'll crash, find a way to not have this happen lol\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading data\")\n",
    "        folder_path = os.path.dirname(write_location)\n",
    "        with open(write_location, 'wb') as file:\n",
    "            for data in response.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                file.write(data)\n",
    "        progress_bar.close()\n",
    "        return write_location\n",
    "    else:\n",
    "        return f\"Exited with {response.status_code} as error\"\n",
    "\n",
    "def ExtractZip(zip_file, extract_path):\n",
    "    \"\"\"\n",
    "    Extract a ZIP file to a specified location.\n",
    "    Args: zip_file (str): The path to the ZIP file to extract; extract_path (str): The path where the ZIP file will be extracted.\n",
    "    Returns: str or file: The path to the extracted folder or an error message if extraction fails.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(extract_path):\n",
    "            os.makedirs(extract_path)\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        with tqdm(total=total_files, desc=\"Extracting data\") as pbar:\n",
    "            for member in zip_ref.infolist():\n",
    "                zip_ref.extract(member, extract_path)\n",
    "                pbar.update(1)\n",
    "    return extract_path\n",
    "\n",
    "def GenerateStationIDs(folderPath):\n",
    "    \"\"\"\n",
    "    Reads the stations file and generates a dict with IDs and the countries\n",
    "    Args: the folderpath to the stations file\n",
    "    Return: dictionary: {ID : Country}; note that {country} is formatted in ISO3116 alpha-2\n",
    "    \"\"\"\n",
    "    with open(folderPath + 'stations.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = lines[17:]\n",
    "        f.close()\n",
    "    reg = r\"[\\s]*(\\d+),([\\w\\W\\s]*),([a-zA-Z]{2})\"\n",
    "    CountryIDs = {}\n",
    "    for line in lines:\n",
    "        m = re.match(reg, line)\n",
    "        if m:\n",
    "            country = m.group(3)\n",
    "            stationId = str(m.group(1)).zfill(5)\n",
    "            CountryIDs[stationId] = country\n",
    "    return CountryIDs\n",
    "\n",
    "def RenameFiles(folderPath, CountryIDs, reg=r\"TG_STAID0(\\d*)\", group=1):\n",
    "    \"\"\"\n",
    "    Renames all the files in a folder if it matches the given group in the regex, then renames the file\n",
    "    Args: the folderpath, dictionary that looks like {regex_match : new_name}, regex, group\n",
    "    Return: none\n",
    "    \"\"\"\n",
    "    for file in os.listdir(folderPath):\n",
    "        match = re.match(reg, file)\n",
    "        if not match:\n",
    "            continue\n",
    "        stationId = match.group(group)\n",
    "        newName = CountryIDs[stationId] + stationId + '.txt'\n",
    "        os.rename(os.path.join(folderPath, file), os.path.join(folderPath, newName))\n",
    "\n",
    "def ConvertAlpha2(code):\n",
    "    return pycountry.countries.get(alpha_2=code).alpha_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb3f3613-9fd6-4538-888e-b90d39bbd8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GenerateTemperatureDataframes(filePath):\n",
    "    \"\"\"\n",
    "    Generates a pandas DataFrame from a CSV file containing temperature data.\n",
    "    Parameters: filePath (str): The path to the CSV file, regex matching on (text/)*(countryName)(number)\n",
    "    Returns: tuple: A tuple containing the country name and the generated DataFrame.\n",
    "    \"\"\"\n",
    "    if re.match(r\"[a-zA-Z/]*/([a-zA-Z\\ ]+)(\\d+)\" ,filePath):\n",
    "        country = re.match(r\"[a-zA-Z/]*/([a-zA-Z\\ ]+)(\\d+)\", filePath).group(1)\n",
    "    else:\n",
    "        print(f\"No match with {filePath}\")\n",
    "        return False, False      \n",
    "    with open(filePath, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None, skiprows=21, names=[\"STAID\", \"SOUID\", \"DATE\", \"TG\", \"Q_TG\"], usecols=[\"DATE\", \"TG\", \"Q_TG\"])\n",
    "    df = df[df[\"Q_TG\"].astype(int).isin([0, 1])]\n",
    "    df[\"TG\"] = df[\"TG\"].astype(float) / 10\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%Y%m%d\").dt.strftime('%Y-%m')\n",
    "    df = df[[\"DATE\", \"TG\"]]\n",
    "    df = df.rename(columns={'DATE': 'Date', 'TG': 'Temperature'})\n",
    "    return country, df\n",
    "\n",
    "def CleanTemperatureDataframes(results, dataframeDict, folderPath = \"data/temperature/\", save = False):\n",
    "    \"\"\"\n",
    "    Cleans and processes temperature dataframes.\n",
    "    Parameters: results (list): A list of tuples containing country names and their respective dataframes.\n",
    "        dataframeDict (dict): A dictionary to store the cleaned dataframes.\n",
    "        folderPath (str): The path to the folder where the cleaned dataframes will be saved.\n",
    "        save (bool): A flag indicating whether to save the cleaned dataframes to disk.\n",
    "    Returns: dict: A dictionary containing cleaned dataframes grouped by country name.\n",
    "    \"\"\"\n",
    "    for result in results:\n",
    "        country = result[0]\n",
    "        df = result[1]\n",
    "        if country in dataframeDict.keys():\n",
    "            dataframeDict[country].append(df)\n",
    "    #Filter out the empty countries:\n",
    "    dataframeDict = {ConvertAlpha2(key): val for key, val in dataframeDict.items() if val}\n",
    "    #Average the temperatures of the same months\n",
    "    for country, dfList in dataframeDict.items():\n",
    "            concated = pd.concat(dfList, ignore_index=True)\n",
    "            dataframeDict[country] = concated.groupby('Date')['Temperature'].mean().round().reset_index()\n",
    "    \n",
    "    \n",
    "    #Legacy Saving Code, I'm unsure if it actually works\n",
    "    if save:    \n",
    "        for key, value in dataframeDict.items():\n",
    "            value.to_csv(folderPath+str(key)+\".csv\", index=False)\n",
    "    return dataframeDict\n",
    "\n",
    "def CombineSavedCSV(folder_path):\n",
    "    #Dit is Legacy Code, ik kan je oprecht niet met zekerheid vertellen of het werkt \n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    combined_df = pd.DataFrame(columns=[\"Date\"])\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(folder_path, file))\n",
    "        df.set_index('Date', inplace=True)\n",
    "        country_name = os.path.splitext(file)[0]\n",
    "        df.rename(columns={'Temperature': country_name}, inplace=True)\n",
    "        combined_df = combined_df.join(df, how='outer')\n",
    "    combined_df = combined_df.reindex(sorted(combined_df.columns), axis=1)\n",
    "    return combined_df\n",
    "\n",
    "def CombineCSVDict(dict):\n",
    "    \"\"\"\n",
    "    Combines multiple pandas DataFrames into a single DataFrame.\n",
    "    Parameters: dict: A dictionary containing the DataFrames to be combined.\n",
    "    Returns: A DataFrame containing data from all input DataFrames, matched on the Date column.\n",
    "    \"\"\"\n",
    "    dfs = [df.set_index('Date').rename(columns={\"Temperature\" : country}) for country, df in dict.items()]\n",
    "    result = pd.concat(dfs, axis=1).reset_index()\n",
    "    result = pd.melt(result, id_vars=['Date'], var_name='Country', value_name='Temperature')\n",
    "    result = result.dropna(subset=['Temperature'])\n",
    "    result = result[result['Date']>= '2000']\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fea7d0c-0dbd-47fd-ad8b-c368d0d52421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadTemperatureData(url, folderPath):\n",
    "    \"\"\"\n",
    "    Downloading AND unzipping, what more do you want?!\n",
    "    \"\"\"\n",
    "    download = DownloadFile(url, folderPath+\"download.zip\")\n",
    "    ExtractZip(download, folderPath)\n",
    "\n",
    "def ClassifyTemperatureData(folderPath):\n",
    "    \"\"\"\n",
    "    Calls both the StationID generator and RenameFiles function; thus generates the station IDs and renames all the files\n",
    "    \"\"\"\n",
    "    dict = GenerateStationIDs(folderPath)\n",
    "    RenameFiles(folderPath, dict)\n",
    "\n",
    "def RemoveFile(file):\n",
    "    \"\"\"\n",
    "    Removes a file\n",
    "    Args: File, the path to the file that will be removed\n",
    "    \"\"\"\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33435f8e-b087-4b91-81b7-21cc993639b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m     p_map(RemoveFile, toClean, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaning leftover files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mTemperatureDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mTemperatureDownloader\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m dataframeDict \u001b[38;5;241m=\u001b[39m {key: [] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m EUList}\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Prepare all the data for processing\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# TODO If internet dies halfway through the download, it fails and the function errors out\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# DownloadTemperatureData(url, folderPath)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ExtractZip(folderPath+\"download.zip\", folderPath)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# ClassifyTemperatureData(folderPath)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m files \u001b[38;5;241m=\u001b[39m [folderPath\u001b[38;5;241m+\u001b[39mfilename \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(folderPath) \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m p_umap(GenerateTemperatureDataframes, files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing the data\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_cpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating temperature mapping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Alles samenkomend ziet het er zo uit:\n",
    "def TemperatureDownloader():\n",
    "    \"\"\"\n",
    "    Downloads, processes, and cleans temperature data from the KNMI Climate Explorer.\n",
    "    \"\"\"\n",
    "    url = \"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_blend_tg.zip\"\n",
    "    folderPath = \"data/\"\n",
    "    EUList = ['AT', 'BE', 'BG', 'HR', 'CY', 'DK', 'EE', 'FI', 'FR', 'DE', 'IE', 'IT', 'LV', 'LU', 'NL', 'NO', 'PL', 'RO', 'ES', 'SE', 'CH', 'GB']\n",
    "    dataframeDict = {key: [] for key in EUList}\n",
    "\n",
    "    # Prepare all the data for processing\n",
    "    # TODO If internet dies halfway through the download, it fails and the function errors out\n",
    "    # DownloadTemperatureData(url, folderPath)\n",
    "    # ExtractZip(folderPath+\"download.zip\", folderPath)\n",
    "    # ClassifyTemperatureData(folderPath)\n",
    "\n",
    "    \n",
    "    files = [folderPath+filename for filename in os.listdir(folderPath) if filename.endswith(\".txt\")]\n",
    "    results = p_umap(GenerateTemperatureDataframes, files, desc=\"Preparing the data\", num_cpus=3)\n",
    "    print(\"Generating temperature mapping...\")\n",
    "    dict = CleanTemperatureDataframes(results, dataframeDict, save=False)\n",
    "    dict = CombineCSVDict(dict)\n",
    "    toClean = [os.path.join(folderPath, file) for file in os.listdir(folderPath) if file.endswith(\".txt\")]\n",
    "    p_map(RemoveFile, toClean, desc=\"Cleaning leftover files\")\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "TemperatureDownloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89cdd2-b1bc-4adb-8f37-b6f921f14239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

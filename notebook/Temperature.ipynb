{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537efa65-314d-485b-978e-84499a716f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in /opt/conda/lib/python3.11/site-packages (22.3.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.11/site-packages (5.17.0)\n",
      "Requirement already satisfied: dash in /opt/conda/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: p_tqdm in /opt/conda/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from pycountry) (68.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from plotly) (23.1)\n",
      "Requirement already satisfied: Flask<2.3.0,>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from dash) (2.2.5)\n",
      "Requirement already satisfied: Werkzeug<2.3.0 in /opt/conda/lib/python3.11/site-packages (from dash) (2.2.3)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /opt/conda/lib/python3.11/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /opt/conda/lib/python3.11/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /opt/conda/lib/python3.11/site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from dash) (4.7.1)\n",
      "Requirement already satisfied: retrying in /opt/conda/lib/python3.11/site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: ansi2html in /opt/conda/lib/python3.11/site-packages (from dash) (1.8.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from dash) (1.5.6)\n",
      "Requirement already satisfied: tqdm>=4.45.0 in /opt/conda/lib/python3.11/site-packages (from p_tqdm) (4.66.1)\n",
      "Requirement already satisfied: pathos>=0.2.5 in /opt/conda/lib/python3.11/site-packages (from p_tqdm) (0.3.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from p_tqdm) (1.16.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.11/site-packages (from Flask<2.3.0,>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.11/site-packages (from Flask<2.3.0,>=1.0.4->dash) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /opt/conda/lib/python3.11/site-packages (from Flask<2.3.0,>=1.0.4->dash) (8.1.7)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /opt/conda/lib/python3.11/site-packages (from pathos>=0.2.5->p_tqdm) (0.70.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from Werkzeug<2.3.0->dash) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycountry pandas regex requests plotly dash p_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97d7df0-fb4b-4e0f-9d6c-50b5c525fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pycountry\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from p_tqdm import p_map, p_umap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08607f46-2f57-4d6c-a88c-7c7a78caba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit zijn meer algehele, saaie helper functies:\n",
    "\n",
    "def FilterEmptyDict(input_dict):\n",
    "    \"\"\"\n",
    "    Filter out empty entries (values) from a dictionary.\n",
    "    Args: input_dict (dict): The dictionary to filter.\n",
    "    Returns: dict: A new dictionary with empty entries removed.\n",
    "    \"\"\"\n",
    "    return {key: val for key, val in input_dict.items() if val}\n",
    "\n",
    "def DownloadFile(url, write_location):\n",
    "    \"\"\"\n",
    "    Download a file from a given URL and save it to a specified location.\n",
    "    Args: url (str): The URL of the file to download; write_location (str): The path where the downloaded file will be saved.\n",
    "    Returns: str or file: The path to the saved file or an error message if the download fails.\n",
    "    \"\"\"\n",
    "    #TODO If internet shits the bed halfway through, it'll crash, find a way to not have this happen lol\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading data\")\n",
    "        folder_path = os.path.dirname(write_location)\n",
    "        with open(write_location, 'wb') as file:\n",
    "            for data in response.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                file.write(data)\n",
    "        progress_bar.close()\n",
    "        return write_location\n",
    "    else:\n",
    "        return f\"Exited with {response.status_code} as error\"\n",
    "\n",
    "def ExtractZip(zip_file, extract_path):\n",
    "    \"\"\"\n",
    "    Extract a ZIP file to a specified location.\n",
    "    Args: zip_file (str): The path to the ZIP file to extract; extract_path (str): The path where the ZIP file will be extracted.\n",
    "    Returns: str or file: The path to the extracted folder or an error message if extraction fails.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(extract_path):\n",
    "            os.makedirs(extract_path)\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        with tqdm(total=total_files, desc=\"Extracting data\") as pbar:\n",
    "            for member in zip_ref.infolist():\n",
    "                zip_ref.extract(member, extract_path)\n",
    "                pbar.update(1)\n",
    "    return extract_path\n",
    "\n",
    "def GenerateStationIDs(folderPath):\n",
    "    \"\"\"\n",
    "    Reads the stations file and generates a dict with IDs and the countries\n",
    "    Args: the folderpath to the stations file\n",
    "    Return: dictionary: {ID : Country}; note that {country} is formatted in ISO3116 alpha-2\n",
    "    \"\"\"\n",
    "    with open(folderPath + 'stations.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = lines[17:]\n",
    "        f.close()\n",
    "    reg = r\"[\\s]*(\\d+),([\\w\\W\\s]*),([a-zA-Z]{2})\"\n",
    "    CountryIDs = {}\n",
    "    for line in lines:\n",
    "        m = re.match(reg, line)\n",
    "        if m:\n",
    "            country = m.group(3)\n",
    "            stationId = str(m.group(1)).zfill(5)\n",
    "            CountryIDs[stationId] = country\n",
    "    return CountryIDs\n",
    "\n",
    "def RenameFiles(folderPath, CountryIDs, reg=r\"TG_STAID0(\\d*)\", group=1):\n",
    "    \"\"\"\n",
    "    Renames all the files in a folder if it matches the given group in the regex, then renames the file\n",
    "    Args: the folderpath, dictionary that looks like {regex_match : new_name}, regex, group\n",
    "    Return: none\n",
    "    \"\"\"\n",
    "    for file in os.listdir(folderPath):\n",
    "        match = re.match(reg, file)\n",
    "        if not match:\n",
    "            continue\n",
    "        stationId = match.group(group)\n",
    "        newName = CountryIDs[stationId] + stationId + '.txt'\n",
    "        os.rename(os.path.join(folderPath, file), os.path.join(folderPath, newName))\n",
    "\n",
    "def ConvertAlpha2(code):\n",
    "    return pycountry.countries.get(alpha_2=code).alpha_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3f3613-9fd6-4538-888e-b90d39bbd8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GenerateTemperatureDataframes(filePath):\n",
    "    \"\"\"\n",
    "    Generates a pandas DataFrame from a CSV file containing temperature data.\n",
    "    Parameters: filePath (str): The path to the CSV file, regex matching on (text/)*(countryName)(number)\n",
    "    Returns: tuple: A tuple containing the country name and the generated DataFrame.\n",
    "    \"\"\"\n",
    "    if re.match(r\"[a-zA-Z/]*/([a-zA-Z\\ ]+)(\\d+)\" ,filePath):\n",
    "        country = re.match(r\"[a-zA-Z/]*/([a-zA-Z\\ ]+)(\\d+)\", filePath).group(1)\n",
    "    else:\n",
    "        print(f\"No match with {filePath}\")\n",
    "        return False, False      \n",
    "    with open(filePath, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None, skiprows=21, names=[\"STAID\", \"SOUID\", \"DATE\", \"TG\", \"Q_TG\"], usecols=[\"DATE\", \"TG\", \"Q_TG\"])\n",
    "    df = df[df[\"Q_TG\"].astype(int).isin([0, 1])]\n",
    "    df[\"TG\"] = df[\"TG\"].astype(float) / 10\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%Y%m%d\").dt.strftime('%Y-%m')\n",
    "    df = df[[\"DATE\", \"TG\"]]\n",
    "    df = df.rename(columns={'DATE': 'Date', 'TG': 'Temperature'})\n",
    "    return country, df\n",
    "\n",
    "def CleanTemperatureDataframes(results, dataframeDict, folderPath = \"data/temperature/\", save = False):\n",
    "    \"\"\"\n",
    "    Cleans and processes temperature dataframes.\n",
    "    Parameters: results (list): A list of tuples containing country names and their respective dataframes.\n",
    "        dataframeDict (dict): A dictionary to store the cleaned dataframes.\n",
    "        folderPath (str): The path to the folder where the cleaned dataframes will be saved.\n",
    "        save (bool): A flag indicating whether to save the cleaned dataframes to disk.\n",
    "    Returns: dict: A dictionary containing cleaned dataframes grouped by country name.\n",
    "    \"\"\"\n",
    "    for result in results:\n",
    "        country = result[0]\n",
    "        df = result[1]\n",
    "        if country in dataframeDict.keys():\n",
    "            dataframeDict[country].append(df)\n",
    "    #Filter out the empty countries:\n",
    "    dataframeDict = {ConvertAlpha2(key): val for key, val in dataframeDict.items() if val}\n",
    "    #Average the temperatures of the same months\n",
    "    for country, dfList in dataframeDict.items():\n",
    "            concated = pd.concat(dfList, ignore_index=True)\n",
    "            dataframeDict[country] = concated.groupby('Date')['Temperature'].mean().round().reset_index()\n",
    "    \n",
    "    \n",
    "    #Legacy Saving Code, I'm unsure if it actually works\n",
    "    if save:    \n",
    "        for key, value in dataframeDict.items():\n",
    "            value.to_csv(folderPath+str(key)+\".csv\", index=False)\n",
    "    return dataframeDict\n",
    "\n",
    "def CombineSavedCSV(folder_path):\n",
    "    #Dit is Legacy Code, ik kan je oprecht niet met zekerheid vertellen of het werkt \n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    combined_df = pd.DataFrame(columns=[\"Date\"])\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(folder_path, file))\n",
    "        df.set_index('Date', inplace=True)\n",
    "        country_name = os.path.splitext(file)[0]\n",
    "        df.rename(columns={'Temperature': country_name}, inplace=True)\n",
    "        combined_df = combined_df.join(df, how='outer')\n",
    "    combined_df = combined_df.reindex(sorted(combined_df.columns), axis=1)\n",
    "    return combined_df\n",
    "\n",
    "def CombineCSVDict(dict):\n",
    "    \"\"\"\n",
    "    Combines multiple pandas DataFrames into a single DataFrame.\n",
    "    Parameters: dict: A dictionary containing the DataFrames to be combined.\n",
    "    Returns: A DataFrame containing data from all input DataFrames, matched on the Date column.\n",
    "    \"\"\"\n",
    "    dfs = [df.set_index('Date').rename(columns={\"Temperature\" : country}) for country, df in dict.items()]\n",
    "    result = pd.concat(dfs, axis=1).reset_index()\n",
    "    result = pd.melt(result, id_vars=['Date'], var_name='Country', value_name='Temperature')\n",
    "    result = result.dropna(subset=['Temperature'])\n",
    "    result = result[result['Date']>= '2000']\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fea7d0c-0dbd-47fd-ad8b-c368d0d52421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadTemperatureData(url, folderPath):\n",
    "    \"\"\"\n",
    "    Downloading AND unzipping, what more do you want?!\n",
    "    \"\"\"\n",
    "    download = DownloadFile(url, folderPath+\"download.zip\")\n",
    "    ExtractZip(download, folderPath)\n",
    "\n",
    "def ClassifyTemperatureData(folderPath):\n",
    "    \"\"\"\n",
    "    Calls both the StationID generator and RenameFiles function; thus generates the station IDs and renames all the files\n",
    "    \"\"\"\n",
    "    dict = GenerateStationIDs(folderPath)\n",
    "    RenameFiles(folderPath, dict)\n",
    "\n",
    "def RemoveFile(file):\n",
    "    \"\"\"\n",
    "    Fucks your mother\n",
    "    Args: File, the path to the file that will be removed\n",
    "    \"\"\"\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33435f8e-b087-4b91-81b7-21cc993639b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdb4908ff0c4a5dbc0645110fce096e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing the data:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating temperature mapping...\n",
      "{'AUT':          Date  Temperature\n",
      "0     1876-01         -6.0\n",
      "1     1876-02         -1.0\n",
      "2     1876-03          4.0\n",
      "3     1876-04         10.0\n",
      "4     1876-05          9.0\n",
      "...       ...          ...\n",
      "1767  2023-04          7.0\n",
      "1768  2023-05         13.0\n",
      "1769  2023-06         18.0\n",
      "1770  2023-07         20.0\n",
      "1771  2023-08         19.0\n",
      "\n",
      "[1772 rows x 2 columns], 'BEL':        Date  Temperature\n",
      "0   2020-10         12.0\n",
      "1   2020-11          9.0\n",
      "2   2020-12          6.0\n",
      "3   2021-01          3.0\n",
      "4   2021-02          5.0\n",
      "5   2021-03          7.0\n",
      "6   2021-04          7.0\n",
      "7   2021-05         12.0\n",
      "8   2021-06         19.0\n",
      "9   2021-07         18.0\n",
      "10  2021-08         17.0\n",
      "11  2021-09         17.0\n",
      "12  2021-10         12.0\n",
      "13  2021-11          7.0\n",
      "14  2021-12          6.0\n",
      "15  2022-01          5.0\n",
      "16  2022-02          7.0\n",
      "17  2022-03          8.0\n",
      "18  2022-04          9.0\n",
      "19  2022-05         15.0\n",
      "20  2022-06         18.0\n",
      "21  2022-07         20.0\n",
      "22  2022-08         21.0\n",
      "23  2022-09         15.0\n",
      "24  2022-10         14.0\n",
      "25  2022-11          9.0\n",
      "26  2022-12          4.0\n",
      "27  2023-01          5.0\n",
      "28  2023-02          6.0\n",
      "29  2023-03          8.0\n",
      "30  2023-04          9.0\n",
      "31  2023-05         14.0\n",
      "32  2023-06         20.0\n",
      "33  2023-07         19.0\n",
      "34  2023-08         18.0, 'CHE':          Date  Temperature\n",
      "0     1901-01         -4.0\n",
      "1     1901-02         -9.0\n",
      "2     1901-03         -3.0\n",
      "3     1901-04          3.0\n",
      "4     1901-05          7.0\n",
      "...       ...          ...\n",
      "1467  2023-04          5.0\n",
      "1468  2023-05         11.0\n",
      "1469  2023-06         16.0\n",
      "1470  2023-07         18.0\n",
      "1471  2023-08         17.0\n",
      "\n",
      "[1472 rows x 2 columns]}\n",
      "[          AUT\n",
      "Date         \n",
      "1876-01  -6.0\n",
      "1876-02  -1.0\n",
      "1876-03   4.0\n",
      "1876-04  10.0\n",
      "1876-05   9.0\n",
      "...       ...\n",
      "2023-04   7.0\n",
      "2023-05  13.0\n",
      "2023-06  18.0\n",
      "2023-07  20.0\n",
      "2023-08  19.0\n",
      "\n",
      "[1772 rows x 1 columns],           BEL\n",
      "Date         \n",
      "2020-10  12.0\n",
      "2020-11   9.0\n",
      "2020-12   6.0\n",
      "2021-01   3.0\n",
      "2021-02   5.0\n",
      "2021-03   7.0\n",
      "2021-04   7.0\n",
      "2021-05  12.0\n",
      "2021-06  19.0\n",
      "2021-07  18.0\n",
      "2021-08  17.0\n",
      "2021-09  17.0\n",
      "2021-10  12.0\n",
      "2021-11   7.0\n",
      "2021-12   6.0\n",
      "2022-01   5.0\n",
      "2022-02   7.0\n",
      "2022-03   8.0\n",
      "2022-04   9.0\n",
      "2022-05  15.0\n",
      "2022-06  18.0\n",
      "2022-07  20.0\n",
      "2022-08  21.0\n",
      "2022-09  15.0\n",
      "2022-10  14.0\n",
      "2022-11   9.0\n",
      "2022-12   4.0\n",
      "2023-01   5.0\n",
      "2023-02   6.0\n",
      "2023-03   8.0\n",
      "2023-04   9.0\n",
      "2023-05  14.0\n",
      "2023-06  20.0\n",
      "2023-07  19.0\n",
      "2023-08  18.0,           CHE\n",
      "Date         \n",
      "1901-01  -4.0\n",
      "1901-02  -9.0\n",
      "1901-03  -3.0\n",
      "1901-04   3.0\n",
      "1901-05   7.0\n",
      "...       ...\n",
      "2023-04   5.0\n",
      "2023-05  11.0\n",
      "2023-06  16.0\n",
      "2023-07  18.0\n",
      "2023-08  17.0\n",
      "\n",
      "[1472 rows x 1 columns]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faacc6b288e544a08ed316d1ced83d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning leftover files:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alles samenkomend ziet het er zo uit:\n",
    "def TemperatureDownloader():\n",
    "    \"\"\"\n",
    "    Downloads, processes, and cleans temperature data from the KNMI Climate Explorer.\n",
    "    \"\"\"\n",
    "    url = \"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_blend_tg.zip\"\n",
    "    folderPath = \"data/\"\n",
    "    EUList = ['AT', 'BE', 'BG', 'HR', 'CY', 'DK', 'EE', 'FI', 'FR', 'DE', 'IE', 'IT', 'LV', 'LU', 'NL', 'NO', 'PL', 'RO', 'ES', 'SE', 'CH', 'GB']\n",
    "    dataframeDict = {key: [] for key in EUList}\n",
    "\n",
    "    # Prepare all the data for processing\n",
    "    # TODO If internet dies halfway through the download, it fails and the function errors out\n",
    "    # DownloadTemperatureData(url, folderPath)\n",
    "    # ExtractZip(folderPath+\"download.zip\", folderPath)\n",
    "    # ClassifyTemperatureData(folderPath)\n",
    "\n",
    "    \n",
    "    files = [folderPath+filename for filename in os.listdir(folderPath) if filename.endswith(\".txt\")]\n",
    "    results = p_umap(GenerateTemperatureDataframes, files, desc=\"Preparing the data\", num_cpus=3)\n",
    "    print(\"Generating temperature mapping...\")\n",
    "    dict = CleanTemperatureDataframes(results, dataframeDict, save=False)\n",
    "    dict = CombineCSVDict(dict)\n",
    "    toClean = [os.path.join(folderPath, file) for file in os.listdir(folderPath) if file.endswith(\".txt\")]\n",
    "    p_map(RemoveFile, toClean, desc=\"Cleaning leftover files\")\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "TemperatureDownloader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
